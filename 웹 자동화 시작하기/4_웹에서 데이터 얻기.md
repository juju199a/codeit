# 4. 웹에서 데이터 얻기
## 01. 크롬 개발자 도구
1. 개발자 도구
  - 웹페이지 > 오른쪽 클릭 > 검사
  - `Elements`

2. td
  - table > tbody > tr > th
  - table data

## 02. Beautiful Soup
1. 설치
  - PyCharm > Preference > 'inter' 검색
  - Project > Project Interpreter
  - beautifulsoup 검색 > beatufulsoup4 설치

2. 또는
  - `pip3 install beautifulsoup4`

3. `html.parser`
  - **BeautifulSoup(rating_page, 'html_parser')**

4. `soup.prettify()`

## 03. 원하는 태그 선택하기 1
1. soup.select('table')
  - select 메소드는 우리가 이전 챕터에서 배웠던 CSS 선택자를 파라미터로 받습니다.

2. `soup.select('td.program')`
  - td 태그이면서 CSS 선택자가 program인 것

3. tag.get_text()
  - for tag in program_title_tags:
  - `print(tag.get_text())`

4. 제목만 모아서 리스트로 만들기
  - program_titles = []
  - program_titles.append(tag.get_text())
  
5. select 메소드
  - 리스트로 반환

6. select_one 메소드
  - HTML 문서 중 가장 위의 하나만 반환 
  - `soup.select_one('td.program')`

## 04. 꿈의 직장 전화번호 모으기 1
1. `BeaturifulSeoup`을 이용해서 받아온 HTML 코드를 정리

2. CSS 선택자
  - phone_num_tags = soup.select('span.phoneNum')

3. 전화번호 빼 오기
  - tag.get_text()

## 05. 원하는 태그 선택하기 2
1. soup.select('td')[:4]
  - 모든 td 중에서 앞에서 4개
  - `리스트 슬라이싱`

2. tag.get_text()

## 06. 리스트 인덱스
1. 슬라이싱
  - `lst[start:stop]`
  - `lst[start:stop:step]`
  - start 인덱스에서 stop-1까지의 요소를 가져온다(잘라낸다)는 뜻입니다.

2. `sliced_list = lst[:8]`
  - 리스트에서 필요한 부분만 잘라냈으니, 이걸 새로운 변수에 저장해서 쓰면 됩니다.

3. range() 함수
  - `range()` 함수는 필요한 인덱스 범위를 만들어 주는 데 사용됩니다.
  - `range()` 함수를 잘 이용하면 원하는 인덱스에 있는 요소들만 접근할 수 있습니다.
  - range(stop)
  - range(start, stop)
  - range(start, stop, step)

## 07. 원하는 태그 선택하기 3
1. 2번째 tr 태그 안에 td
  - `soup.select('tr')`
  - `soup.select('tr')[1]`

2. `tr_tag.select(*)`
  - 원래는 tr_tag.select('td') 인데
  - tr 태그 밑에 td 밖에 없어서 `*`를 쓸 수 있다.
  - **별표(*)는 태그 종류와 상관 없이 모든 자식 태그를 가져오고 싶을 때 유용하게 쓰입니다.**

## 08. 꿈의 직장 전화번호 모으기 2
1. branch_tags = soup.select('div.branch')
  - `div` 태그에 대한 선택자(div)와 class="branch"에 대한 선택자(.branch)를 붙여 써 줬습니다.

## 09. find, find_all 메소드
1. `.select_one()`, `.select()` 메소드 활용

2. `.find()`, `.find_all()` 메소드 활용
    - find()는 select_one() 과 비슷
    - find_all()은 select()와 비슷
    - **하지만 CSS 선택자를 쓰지 않고 여러 파라미터를 활용합니다.**

3. 태그 이름 사용
  - soup.find_all('tagname')
  - `soup.find_all('p')`
  - `soup.find_all(['p', 'a'])`

4. 모든 태그 선택
  - tag.find_all(True)

5. 속성 사용
  - soup.find_all('tagname', attr1='val1', attr2='val2', ...)
  - `soup.find_all('p', id="some-id", class_="some-class")`
  - **class는 `class_`로 써 줘야 합니다. 파이썬에서 `class`는 클래스를 만드는 데 사용되는 이미 예약된 단어이기 때문이죠**
  - 마지막으로 find(), find_all()은 특정 속성이 있는지 없는지를 조건으로 사용할 수 있습니다.
  - 속성 값 대신 Trud나 False를 써 주면 됩니다.
  - soup.find_all('p', id=True, class_=False)

6. 중첩 태그
  - find(), find_all()은 중첩에 대한 문법이 없기 때문에, 
  - 태그 안에 중첩된 태그를 찾으려면 태그에 find(), find_all()을 사용해야 합니다.
  - soup.select('div.some-class p')
  - div_tag = soup.find('div', class_='some-class')
  - div_tag.find_all('p')

7. Selenium
  - Selenium이라는 도구에 대해 배워 볼 건데, Selenium을 사용할 때는 CSS 선택자를 계속 쓸 겁니다.

## 10. 태그 중복성 확인하기
1. soup.select('ul.popular__order li')
  - ul 태그 안에 popular__order CSS 선택자 속에 li

## 11. 태그에서 텍스트 빼 오기
1. 각 태그 안에 있는 텍스트 가져오는 두 가지 방법
  - get_text 메소드 사용
  - li 태그 안에서 get_text 해 주면 `순위와 아티스트 이름`이 합쳐서 리턴된다.
  - `for tag in soup.select('ul.popular__order li')`
  - `print(tag.get_text())`
  - `tag.get_text().strip()`

2. 두 번째 방법 `list(tag.stripped_strings)` **이것만 써라**
  - print(tag.strings)
  - 이 strings는 태그 안에 있는 모든 텍스트 요소들을 따로 리턴해 줍니다.
  - 그런데 리스트로 만들어줘야 한다.
  - print(list(tag.strings))
  - 그 이유는 tag.strings 안에 있는 텍스트 요소들을 하나씩 순서대로만 접근할 수 있기 때문입니다.
  - 태그 안에서 원하는 텍스트 요소를 빼오려면 `tag.strings`를 리스트 형식으로 만들어줘야 합니다.
  - '\n' 을 빼주기 위해서
  - `print(list(tag.stripped_strings))`
  - `print(list(tag.stripped_strings)[1])`
  
## 12. 파이썬 문자열 다루기
1. Strip
  - print(message.strip())

2. Split
  - split()

3. Join
  - join()

4. Replace
  - replace()

5. Lower, Upper, Capitalize

6. 유의사항
  - 모든 문자열 메소드는 문자열 자체를 변형하는 것이 아니라, 변형된 문자열을 리턴하는 겁니다.

## 13. 검색어 순위 받아오기
1. soup을 만들어 줍니다.

2. for tag in soup.select('ul.rank__order li')

3. list(tag.stripped_strings)

4. print(list(tag.stripped_strings))

5. list(tag.stripped_strings)[2]

## 14. 태그에서 속성 빼 오기
1. soup.select_one('img')['src']
  - 원하는 속성 값을 가져오려면 그냥 여기 이런 식으로 
  - 이런 괄호에다가 속성의 이름을 적어주면 됩니다.

2. 사전 형태
  - 사실 태그의 모든 속성은 사전 형태로 되어 있는데요.
  - soup.select_one('img').attrs 를 쓰면,
  - 태그의 모든 속성을 확인할 수 있는데요.
  - 태그의 속성은 이런 식으로 사전 형태로 저장되어 있습니다.

## 15. Beautiful Soup 더 간결하게
1. `soup.tagname`
  - soup.select_one('tagname')과 동일

2. tag.tagname
  - tag.select_one('tagname')과 동일

3. .tagname 문법을 쓰면
  - `div_tag = soup.select_one('div.data')`
  - `title = div_tag.h2.get_text()`
  - `content = div_tag.p.get_text()`
  - `link = div_tag.a['href']`

```
    <div class="data">
      <h2>제목</h2>
      <p>내용</p>
      <a href="www.example.com">링크</a>
    </div>
```

4. 메소드 체이닝
```
<div class="data">
    <div>
    <h2>제목</h2>
    <p>내용<b>키워드</b>내용</p>
    <a href="www.example.com">링크</a>
    </div>
</div>
```
  - `div_tag = soup.select_one('div.data')`
  - `keyword = div_tag.div.p.b.get_text()`
  - `print(keyword)`

## 16. Beautiful Soup 정리 노트
1. Beautiful Soup 라이브러리

2. Beautiful Soup 임포트

3. BeautifulSoup 만들기
  - BeautifulSoup을 만들 때 쓰이는 `html.parser`는 HTML 코드를 정리해 줍니다.
  - 일반적으로 parser는 문서를 읽어 들여서 프로그램이 쉽게 사용할 수 있는 형식으로 변환시켜 주는 툴입니다.

4. 필요한 태그 가져오기
  - `.select()`
  - `.select_one()`

5. 태그에서 정보 가져오기
  - tag.get_text()
  - list(tag.strings)
  - list(tag.stripped_strings)
  - .get_text()
  - .strings는 list()로 감싸 줘야 합니다.
  - .stripped_strings

6. **매우 중요** 속성 가져오기
  - tag['attr']
  - tag.attrs

## 17. 데이터를 엑셀 파일로
1. 워크시트
  - 표 형식으로 저장된다.

2. openpyxl 라이브러리
  - pip3 install openpyxl

3. 라이브러리 import
  - from openpyxl import Workbook

4. 새로운 Workbook 만들기
  - wb = Workbook(write_only=True)
  - 엄청나게 많은 데이터는 `write_only`를 써주는 것이 좋다.

5. Sheet 만들기
  - ws = wb.create_sheet('TV Ratings')

6. 작성
  - we.append(['순위', '채널', '프로그램', '시청률'])

7. 엑셀 파일 저장
  - wb.save('시청률_2010년 1월 1주차.xlsx')

## 18.openpyxl 정리 노트
1. 라이브러리 임포트
  - `from openpyxl import Workbook`

2. 워크북 생성
  - `wb = Workbook()`
  - `wb = Workbook(write_only=True)`
  - 엑셀 파일을 워크북이라고 합니다.
  - 워크북을 만들기 위해선 `Workbook()`을 쓰면 되는데요.
  - 파일에서 데이터를 읽어 오지 않고, 데이터를 저장하기만 하는 경우 `write only 모드`를 써 주는 것이 `퍼포먼스`에 도움이 됩니다.
  - write only 모드는 `write_only=True로 설정해 줄 수 있습니다.

3. 워크시트 생성
  - `ws = wb.create_sheet()`
  - `ws = wb.create_sheet('워크시트_이름')`

4. 행 추가
  - `ws.append([data1, data2, data3])`
  - 워크시트에 행을 추가하려면 행 요소를 리스트로 만들어서 ws.append()에 넣어 줍니다.
  - append는 '무언가를 붙이다`라는 뜻을 가지고 있습니다.

5. 워크북 저장
  - `wb.save('워크북_이름.xlsx')`
  - 워크북에 모든 데이터를 써 줬으면, 워크북을 저장해 줘야 합니다.
  - `wb.save()` 메소드를 쓰고, 파일 이름을 파라미터로 넣어 줍니다.
  - .xlsx 확장자도 잊지 마세요!

## 19. 데이터를 CSV 파일로
1. CSV 모듈 임포트
  - `import csv`

2. CSV 파일 생성
  - `csv_file = open('file_name.csv', 'w')`
  - `csv_write = csv.writer(csv_file)`

3. 행 추가
  - `csv_writer.writerow([data1, data2, ...])`
  - **`.writerow()`** 메소드를 활용하면 됩니다.
  - ws.append()와 비슷하지만, 쓸 수 없다.

4. CSV 파일 닫기
  - `csv_file.close()`

## 20. 꾼의 직장 전화번호 모으기 3
1. 엑셀의 경우
  - 워크시트 생성 워크시트 이름은 따로 설정 안 해 주셔도 됩니다.
  - `wb = Workbook(write_only=True)`
  - `ws = wb.create_sheet()`

2. 엑셀의 append
  - `ws.append(['지점 이름', '주소', '전화번호'])`

3. 엑셀의 파일 닫기
  - `wb.save('오렌지_보틀.xlsx')`

4. CSV의 경우
  - CSV파일과 csv writer를 만들어 줍니다.
  - `csv_file = open('오렌지_보틀.csv', 'w')`
  - `csv_writer = csv.writer(csv_file)`

5. CSV의 writerow
  - `csv_writer.writerow(['지점 이름','주소', '전화번호'])`

6. CSV의 파일 닫기
  - `csv_file.close()`

## 21. 연도별 시청률 데이터 엑셀 파일로 정리해 보기
1. row 만들기
```
row = [
  period,
  td_tags[0].get_text(),
  td_tags[1].get_text(),
  td_tags[2].get_text(),
  td_tags[3].get_text(),
]
ws.append(row)
```

## 22. SBS 프로그램 엑셀 파일로 저장해 보기

