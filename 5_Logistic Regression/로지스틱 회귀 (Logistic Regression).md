### 로지스틱 회귀

1. 선형회귀는 데이터를 분류하고 싶을 때는 잘 사용하지 않는다.
    - 예외적인 1개의 데이터에 너무 민감하게 작용한다.

2. 로지스틱 회귀
    - 분류는 할 때는 선형 회귀 대신에 로지스틱 회귀를 사용합니다.
    - 일차 함수를 찾는 것이 아니라 시그모이드 함수를 찾는 것이다.
    - 0과 1 사이를 결과를 냅니다.
    - x가 크면 1이 되고,
    - x가 작으면 0이 된다.
    - 예외적인 1개의 데이터에 민감하게 반응하지는 않는다.
    
3. 질문
    - 로지시틱 회귀는 회귀가 아니라 분률를 하기 위해서 쓰인다는데, 왜 이름이 로지스틱 회귀일까요?
    - **사실 따지고 보면 시그모이드 함수 결과값도 결국 0과 1 사이의 연속적인 값이기 때문에 회귀라고 볼 수 있습니다.**
    - 그래서 로지스틱 분류가 아니라 로지스틱 회귀라고 부릅니다.
    - 우리는 주로 시그모이드 결과값이 **0.5 보다 큰지 작은지** 보고 결국 분류를 합니다. 그러니까 이름이 로지스틱 회귀이지만, 사용하는 것은 주로 분류라는 점 기억해 주시길 바랍니다.

4. 가설함수
    - 입력 변수를 받아서 목표 변수를 예측해 주는 함수

5. 로그 손실 (log-loss / cross entropy)
    - hx 는 예측값, ㅛ는 실제 값
    - 가능한 목표가 1과 0밖에 없다.
    - 로지스틱 회귀의 손실 함수는 평균 제곱 오차를 사용하지 않습니다.
    - 대신 **로그 손실**, 영어로는 log loss라는 걸 사용합니다. 좀 더 어려운 표현으로는 cross entropy라고도 합니다.
    - 손실의 정도를 로그 함수로 결정하기 때문에 로그 손실!

6. 로지스틱 회귀 손실 함수
    - 로그 손실
    - 모든 데이터의 로그 손실을 계산한 후, 평균을 낸다.
    - 손실함수의 인풋은 세타인데요. 가설함수는 세터를 어떻게 설정하느냐에 따라 바뀌는 거잖아요.
    - 그래서, 어떤 세타값을 설정하느냐에 따라 학습데이터의 손실이 달라지는 것입니다.
    - 그래서, 손실함수의 인풋은 세타인거죠.

7. 로지스틱 회귀 경사 하강법
    - 손실을 최소화하는 방법
    - 처음에는 세터를 0 또는 임의로 설정

8. 로지스틱 회귀 가정 함수
    - return sigmoid( X @ theta )

9. 분류가 3가지 일때
    - 어떤 이메일이 직장 메일의 확률을 예측하는 가설 함수입니다: h0 -> 60%
    - 다 했으면, 친구 메일인지 아닌지: h1 -> 0.45
    - 다 했으면, 스팸 메일인지 아닌지: h2 -> 0.78
    - 이메일을 각각 넣습니다.
    - 0.78이 가장 높기 때문에 스팸 메일로 판단한다.

10. 실습
    - 분류값이니까 답이 0,1,2 밖에 없죠?
    - 예측을 잘 했는지는 어떻게 평가할 수 있을까요?
    - **사실 분류 모델을 평가하는 것은 회귀 모델보다 훨씬 직관적이고 간단합니다.**
    - 그냥 예측한 것 중에 몇 퍼센트가 올바르게 분류 됐는지 확인하면 되겠죠?
    - 로지스틱 모델의 score 메소드를 쓰고, 첫번째 파라미터로 Test 셋의 인풋을 넣고, 두번째 파라미터로 Test의 셋의 실제 결과를 넣습니다.
    - 

 


