# 4. 딥 러닝 모델의 성능을 높이는 다양한 방법
## 01. 딥 러닝 모델의 최적화가 어려운 이유

1. 딥 러닝 모델의 최적화가 어려운 이유
    - 딥 러닝 모델의 효과적인 최적화는 여러 복잡한 요소의 영향을 받습니다.
    - 이런 원인을
        - **모델의 비선형성**
        - **고차원성과 과적합**
        - **그래디언트 소실 문제**
        - **하이퍼 파라미터**의 민감성
    - 4가지로 나눠서 살펴보기로 하겠습니다.

2. 모델의 비선형성
    - 비선형 활성화 함수를 도입하여 모델이 더 복잡한 패턴을 학습할 수 있도록 했다.
    - 비선형성은 모델에 더 많은 표현력을 부여 하지만,
    - 손실 함수의 표면을 복잡하게 만들어, **전역 최솟값(Global Minimum)**을 찾기 어렵게 합니다.

3. 고차원성과 과적합
    - 현대의 딥 러닝 모델은 수백만에서 수십억개의 파라미터를 포함하고 있는 경우가 많습니다.
    - 여기서 **파라미터**란 신경망에서 학습하는 동안 조정되는 가중치와 편향을 의미합니다.
    - 예를 들어 GPT-3라는 모델의 경우 약 1750개의 파라미터를 사용해 학습되었다고 알려져 있습니다.
    - 많은 파라미터를 가진 고차원 모델은 데이터에서 매우 복잡한 패턴을 학습할 수 있지만, 
    - 동시에 **과적합의 위험도** 커집니다.
    - **과적합**은 모델이 지나치게 훈련 데이터에만 맞춰져 있어, 새로운 데이터에 대해 일반화 성능이 떨어지는 현상을 말한다.
    - 보통 학습 데이터에 비해 **파라미터**가 지나치게 많으면, 과적합의 위험이 커진다고 알려져 있습니다.
    - 이를 방지하기 위해 **데이터 증강**, **드롭아웃**, **정규화 기법** 등의 기법이 사용될 수 있다.
    - 이런 기법들을 적절히 사용하는 것이 모델 설계에서 중요합니다.

4. 그래디언트 소실(Gradient Vanishing)
    - 이 현상은 네트워크가 깊어질 수록, 즉 많은 레이어를 거치면서 발생한다.
    - 가중치에 대한 손실 함수의 미분값이 점점 작아져서 앞쪽 층의 가중치 업데이트가 거의 이루어지지 않게 되는 현상입니다.
    - 즉, 갈수록 **그래디언트**가 소실되어 학습이 제대로 이루어지지 않게 되는 문제라고 할 수 있습니다.
    - 여기서 그래디언트 소실이 발생하는 주된 문제는 신경망에서 사용하는 **활성화 함수** 때문인데,
    - 예를 들어, 시그모이드 함수는 출력값의 범위가 0~1로 제한되어 있다. 
    - 이 함수를 계속해서 미분하면, **그래디언트 값이 계속 작아지게 됩니다.**
    - 가장 큰 값이 0.25이고, 양 끝에 위치한 미분값이 0으로 수렴하게 되는 것을 보면 알 수 있다.
    - 신경망이 깊어질 수록, 이러한 현상은 더욱 누적되고, 
    - 결국에는 초기치의 가중치들이 **거의 업데이트되지 않는 상태**에 이르게 된다.
    - 이러한 문제를 해결하기 위해, 
        - 그래디언트 소실에 **덜 민감한 활성화 함수**를 사용하거나 
        - 적절한 **가중치 초기화** 방법을 사용할 수 있고,
        - **배치 정규화** 라는 방법도 사용될 수 있다.

5. 하이퍼 파라미터의 민감성
    - 하이퍼 파리미터는 모델의 **학습률, 배치크기, 층의 수**와 같이 모델이 학습하기 전에 설정되는 변수들로
    - 이들을 적절하게 조정하는 것은 최적의 모델 성능을 달성하기 위해 매우 중요합니다.
    - 적절한 하이퍼 파라미터를 찾는 과정은 시행착오와 많은 실험을 필요로 하고, 
    - 때로는 자동화된 방법을 사용하여 이 과정을 효율화 할 수도 있습니다.
    - 이러한 여러가지 문제 때문에, 딥러닝의 모델의 최적화는 매우 도전적인 과제라고 할 수 있다.

## 02. 딥 러닝 모델링 시 고려할 사항
1. 하이퍼 파리미터
    - 모델의 학습 과정에서 사용자가 사전에 설정해야 하는 값
    - 모델의 성능 최적화를 위해 중요한 역할을 합니다.
    - 하이퍼 파리미터는 딥 러닝 학습 전에 설정되며, 학습 과정을 제어 하는데 사용됩니다.
    - 모델의 학습 속도, 안정성, 최종 성능에 직접적인 영향을 미칩니다.
    - 적절한 하이퍼 파라미터 설정은 과적합을 방지하고, 학습 시간을 효줄적으로 관리하며, 전체적인 모델 성능을 최적화 하는데 매우 중요한 역할을 한다.
    - 하이퍼 파리머터의 종료를 크게 4가지로 나눈다.
        - **배치 크기 (Batch Size)**
        - **학습률 (Learning Rate)**
        - **에폭 수 (Epoch)**
        - **옵티마이저 (Optimizer)**
    
2. 배치 크기 (Batch Size)
    - 한 번에 학습 단계에 사용되는 데이터의 개수를 의미한다.
    - 이는 모델이 학습하는 데이터의 양을 결정해서 메모리 사용량과 학습 속도에 큰 영향을 미칩니다.
    - 배치 크기가 작으면 메모리 요구 사항을 줄이고, 모델의 매개변수가 **더 자주 업데이트** 되도록 하여 빠른 학습을 가능하게 합니다.
    - 하지만 너무 작으면, 결과의 변동성이 커져 학습 과정이 불안정해 질 수 있어요.
    - 반대로 배치 크기가 크면, 메모리 요구량을 늘리고, 학습을 비교적 안정적으로 만들지만, 과적합의 위험에 증가시킬 수도 있습니다.

3. 학습률 (Learning Rate)
    - 모델의 가중치를 얼마나 큰 단계로 업데이트 할지 결정하는 값입니다.
    - 역전파 과정에서 계산된 **그래디언트**에 학습률을 곱해 가중치를 업데이트 하게 된다.
    - W(new) = W(old) - 알파*(Gradient)
    - 알파가 학습률입니다.
    - 그래디언트를 기반으로 얼만큼 값을 조정할지를 결정하는 역할을 하죠.
    - 기존 가중치 값인 W(old)가 있고, 학습률 알파에 그래디언트를 곱해서 빼주면 경사 하강법 적용 후 업데이트된 가중치 W(new)가 나옵니다.
    - 학습률이 너무 낮으면 학습이 지나치게 느려질 수 있다.
    - 반면에 학습이 너무 높으면, **손실 함수가 최소값 주변에서 요동**을 치거나 발산할 수 있어, 최적화 과정에서 실패할 수 있습니다.

4. 에폭 수 (Epoch)
    - 전체 훈련 데이터셋이 네트워크를 통과하는 횟수를 뜻하는데요.
    - 에폭 수를 충분히 설정해 줘야 모델이 **데이터의 패턴**을 잘 학습할 수 있다.
    - 에폭 수가 너무 많으면 학습 시간이 길어지고 과적합을 초래할 수 있습니다.

5. 배치 크기 (Batch Size) vs 에폭 수 (Epoch)
    - 배치 크기: 모델이 한 번의 학습 단계에서 처리하는 데이터의 양
    - 즉, 학습 과정에서 한 번에 메모리에 로드되어 처리되는 샘플의 수를 나타낸다.
    - 따라서 모델의 업데이트 속도와 메모리 사용량에 직접적인 영향을 미칩니다.
    - 반면, 에폭은 전체 훈련 데이터셋이 네트워크를 한 번 완전히 통과하는 횟수를 의미합니다.
    - 즉, 모든 훈련 데이터가 모델을 통해 한 차례 학습되는 것을 하나의 에폭으로 칩니다.

6. 옵티마이저 (Optimizer)
    - 최적화 알고리즘. 즉 옵티마이저는 손실 함수를 최소화 하기 위해 모델의 가중치를 어떤 방식으로 업데이트 할지 결정하는 역할을 합니다.
    - 예를 들어 **확률적 경사 하강법 (SGD)**은 가장 기본적인 형태라고 할 수 있고, 
    - **모멘텀 (Momentum)** 이나 **아담(Adam)**과 같은 알고리즘도 있다.
    - 각 알고리즘은 특정 문제에 더 적합할 수 있으므로 여러 알고리즘을 실험해서 최적의 선택을 하는 것이 좋습니다.

## 03. ReLU (Rectified Linear Unit) 함수
1. 활성화 함수 (Activation Function)
    - 활성화 함수는 신경망의 각 뉴런에서 입력 신호의 총합을 받아 이를 출력 신호로 변환하는 역할을 합니다.
    - 이 함수들은 주로 비선형 형태로 되어 있어, 신경망이 단순한 선형 문제를 넘어서 좀 더 복잡한 문제를 해결할 수 있게 도와준다.
    - 비선형 활성화 함수 덕분에 딥 러닝 모델은 다양한 패턴과 관계를 효과적으로 모델링 할 수 있습니다.
    - 일단 가중합 연산을 통해 구한 값을 비선형 활성화 함수를 통해 변형해 주고, 이를 최종 신경망에 출력값으로 출력하는 형태라고 이해할 수 있어요.
    - 활성화 함수의 선택은 모델의 학습 능력과 성능에 직접적인 영향을 미칩니다.
    - 과거 부터 현재까지 여러 활성화 함수가 개발 되었고, 각각의 함수는 특정 상황에서 장점을 가진다.

2. 시그모이드 함수
    - 초기 신경망에서 널리 사용되었다.
    - 깊은 신경망에서는 그래디언트 소실 문제와 비선형성이 약해지는 문제로 인해 성능이 저하될 수도 있어요.

3. Tanh 함수
    - **하이퍼볼릭 탄젠트** 라는 함수도 있는데요.
    - 시그모이드와 비슷하게 생겼다.
    - 시그모이드의 변형이다.
    - 시그모이드는 출력 범위가 0~1인데, 이것은 출력 범위를 -1~1로 확장합니다.
    - 중심에 있는 값이 0이 되어서, 학습 초기에는 더 빠른 수렴을 도울 수 있으나, 
    - 깊은 신경망에서 여전히 그래디언트 소실 문제가 발생할 수 있습니다.

4. ReLU(Rectified Linear Unit) 함수
    - **렉티파이드 리니어 유닛** 함수는 보통 **렐루**라고 줄여서 부르는데요.
    - 이 함수는 현대 신경망에서 가장 인기 있는 활성화 함수라고 할 수 있어요.
    - 수식을 보면 앞에 max가 씌어져 있다.
    - 양수 값이 들어가면 그대로 출력하지만, 만약에 음수를 입력 받으면 0을 출력하게 되는 것이다.
    - 이를 미뤄 봤을 때, 렐루는 **입력이 양수일 때 그래디언트가 1**이 됨으로 
    - 이 범위에서는 **그래디언트가 감소하지 않습니다.**
    - 이는 깊은 신경망에서도 정보와 그래디언트가 층을 통과 하면서 사라지지 않고,
    - 역전파 동안 효과적으로 전달 될 수 있도록 합니다.
    - 결과적으로 **깊은 층의 가중치가 활성화 상태에서 지속적으로 업데이트** 될 수 있습니다.
    - 그런데, 렐루는 입력이 0 이하인 경우 출력이 0이 된다.
    - 그러면 그래디언트도 0이 됩니다.
    - 음수 입력에서는 **뉴런이 완전히 비활성화** 될 수 있다.
    - 이 현상은 **죽은 뉴런** 문제로 알려져 있으며, 

5. 리키 렐루 (Leaky Relu) 함수
    - 뉴런이 이 상태에 이르면, 학습 과정 중에 해당 뉴런이 다시 활성화 되거나, 학습에 기여하는 것이 매우 어려워진다.
    - 이는 특히 음수 입력이 지속적인 경우, 네트워크의 해당 부분이 실질적으로 학습에서 제외되는 결과를 초래할 수 있습니다.
    - 이 문제를 개선하기 위해 **Leaky Relu** 함수가 등장했습니다. 리키 렐루
    - 함수의 수식은 max(ax,x)로 생겼다.
    - 여기서 a는 0.01과 같은 매우 작은 값을 주로 사용합니다.
    - 즉 음수 입력에서도 아주 작은 기울기를 허용함으로써 모든 입력에 대해서 그래이디언트를 유지하려고 하는 거죠.
    - 이는 렐루(ReLu)의 장점을 유지하면서도 뉴런이 죽는 문제를 줄여 줍니다.

## 04. 다양한 경사 하강법 알아보기
1. 배치 경사 하강법 (Batch Gradient Descent)
    - 역전파의 근간이 되는 가장 기본적인 최적화 알고리즘은 **경사 하강법** 입니다.
    - **배치 (Batch)**는 **이터레이션(iteration)**이라고 부르는 한 번의 학습 단계에서 사용되는 학습 데이터의 묶음인데요.
    - 전체 데이터를 다 학습하면, **1 에폭**을 학습한 것이 됩니다.
    - 배치 경사 하강법이라고 하는 방식은 방금 본 것처럼 **전체 학습 데이터셋**에 대한 에러를 구한 뒤,
    - 기울기를 한 번만 계산하여 모델의 파라미터를 업데이트 하는 방식을 의미합니다.
    - 이 과정을 통해 한번에 모든 데이터에 대한 정보를 고려하여 **가중치를 업데이트** 합니다.
    - 그러나 **대규모 데이터셋에 대해서는 계산 비용이 매우 높고,** 빠르게 수렴하는 것이 어려울 수 있다.
    - 이렇나 비효율성 문제를 개선하기 위해 **확률적 경사 하강법** 이라는 것이 등장했는데요.

2. 확률적 경사 하강법 (Stochastic Gradient Descent, SGD)
    - **스톡캐스틱 그래디언트 디센트**라고 하고 그냥 SGD라고 줄여서 부르기도 합니다.
    - 확률적 경사 하강법은 1번의 이터레이션에서 무작위로 선택된 하나의 데이터 샘플을 사용하여, 
    - 그래디언트를 계산하고, 가중치를 업데이트 합니다.
    - 이는 전체 입력데이터로 가중치와 편향이 업데이트 되는 것이 아니라, 그 안의 일부 데이터 만을 이용한다는 의미입니다.
    - 이 방법은 기본적이지만, 많은 문제에서 효과적일 수 있습니다.
    - 무작위성 때문에, **지역 최솟값에서 벗어나 전역 최솟값을 찾을 가능성**을 주기도 하고
    - 계산 속도가 배치 경사 하강법에 비해, 매우 빠르다는 장점이 있죠.
    - 그러나 이 방법은 **경사의 추정이 불안정하여 학습 과정이 매끄럽지 않을 수 있다**라는 단점도 있습니다.

3. 미니배치 경사 하강법 (Minibatch Gradient Descent)
    - 두 개의 절충안이 **미니배치 경사 하강법**이 있다.
    - 현재 최신 딥러닝 기술에서 가장 많이 사용되고 있는 방법입니다.
    - 전체 데이터셋을 **미니 배치** 라는 그룹들로 나누고, 
    - 각 미니 배치에 대해 독립적으로 경사를 계산한 후 모델의 매개변수에 업데이트 한다.
    - 이 과정은 전체 데이터셋이 모두 처리될 때까지 반복
    - 예를 들어 1000개의 학습셋에서 배치 사이즈를 100으로 잡았으면 **총 10개의 미니 배치**가 나옵니다.
    - 이 100개씩의 미니 배치를 갖고, 1번씩 경사 하강법을 진행해요.
    - 즉, **1에폭 당 총 10번의 업데이트를 진행한다.**
    - 미니 배치를 사용하는 주된 장점은 메모리 효율성과 계산 속도 입니다.
    - 전체 데이터를 한번데 메모리에 로드할 필요 없이, 작은 배치만 처리하기 때문에, 
    - 특히 큰 데이터셋을 다룰 때 효과적인데요.
    - 또한 각 배치 처리가 빠르기 때문에, 전체 모델 업데이트가 빠르게 이루워지며 
    - 이는 학습 과정을 가속화 합니다.
    - 미니 배치의 무작위 선택은 모델이 **지역 최솟값에 갇히는 것을 방지하는데 도움**을 줄 수도 있어요.
    - 그러나 미니 배치 경사 하강법은 **배치 크기와 학습률** 등의 하이퍼 파리미터에 매우 민감합니다.
    - 너무 작은 배치 크기는 모델 업데이트 시 불안정성을 초래할 수 있고, 너무 큰 배치 크기는 계산 효율을 떨어 뜨리고, 지역 최솟값에서 벗어나기 어렵게 만들 수도 있습니다.

## 05. 다양한 Optimizer 알아보기
1. 여러 가지 최적화 알고리즘 (Optimizer)
    - **최적화 알고리즘**은 신경망에서 **가중치를 업데이트 하는 방법**을 의미하는데요.
    - 각 알고리즘의 원리를 알아 두면, 나중에 보다 심화된 문제에 접근할 때도 도움이 된다.
    - 배치 경사 하강법과 확률적 경사 하강법을 발전시킨 다양한 최적화 기법들이 있다.
    - 크게 3가지 카테고리로 나눌 수 있다.
        - **Momentum 계열**
        - **Adagrad 계열**
        - **Adam 계열**

2. 모멘텀 (Momentum)
    - 모멘텀을 번역하면 **관성**이다.
    - 어떤 물체가 기존에 움직이는 방향으로 계속 움직이려는 경향을 의미하는 물리학 용어이다.
    - 딥러닝에서도 이것과 비슷하게 경사 하강법에서 **이전 업데이트 방향을 고려해서** 가중치 업데이트를 진행하는 방식을 모멘텀이라고 합니다.
    - 이때, **이전에 움직였던 스텝 방향**을 고려하게 된다.
    - X(t) = X(t-1) - V(t) (모멘텀을 고려한 모델 가중치 업데이트)
    - X(t) : 현재 업데이트를 해야할 가중치, t는 현재 타임스텝
    - X(t-1) : 이전 스템의 가중치
    - V(t) : **모멘텀이 적용된 그래디언트 백터** 라고 보면 된다.
    - V(t) = 감마 * V(t-1) + η * f(X(t-1))
    - V(t-1) : 이전 타임 스텝에서의 이동 벡터 
    - 감마: 관성계수값. **관성계수는 1보다 조금 작은 0.9 정도 값으로 설정하는 경우가 많습니다.
    - η: **학습률 에타(eta)**
    - t-1번째 X의 그래디언트 값의 곱을 더하면 된다.

3. Adagrad (아다그라드)
    - 움직이는 스텝 사이즈. 즉 학습률을 조절하는 것에 초점을 맞추는 최적화 방법론 들도 있는데요.
    - 대표적으로 아다그라드 라는 것이 있습니다.
    - 매개변수에 대해 학습률을 동적으로 조정하는 최적화 알고리즘입니다.
    - 이 방법은 자주 업데이트 되는 매개변수의 학습률을 점차 감소 시키고
    - 드물게 업데이트 되는 매개변수의 학습률을 상대적으로 높에 유지하여 
    - 각 매개변수가 적절한 속도로 학습되도록 돕습니다.
    - 자주 업데이트 되는 가중치는 잦은 업데이트로 최저값에 얼추 가까워졌다고 보고 
    - 학습률을 점차 감소시켜 최저값을 잘 찾을 수 있도록 하는 것이다.
    - 반면 드물게 업데이트되는 가중치일 경우 
    - 최저값을 더욱 적극적으로 찾을 수 있도록 학습률을 높에 유지 합니다.
    - 이러한 방법은 각 매개 변수가 적절한 속도로 학습되도록 돕죠.
    - 아다그라드를 수식으로 나타내면 
    - g(t): t번째 time step까지의 기울기를 누적한 값입니다.

4. RMSProp (알엠에쓰프롭)
    - 하지만, 학습이 지속되며 점점 가중치 갱신량이 0이 되는 문제가 있을 수 있다.
    - 이를 개선하기 위해, 과거의 기울기는 조금만 반영하고, 
    - 최신의 기울기를 많이 반영하는 **RMSProp**이르는 것이 등장했습니다.
    - g(t)를 계산하는 것이 Adagrad와 다르다.
    - 감마는 지수이동평균 계수인데, Adgrad에서 가중치 업데이트가 되지 않는 문제를 보완하는 역할을 한다.
    - 참고로 감마값이 높을 수록 과거 데이터를 더 높은 비중으로 고려하는 효과가 있습니다.

5. Adam (아담)
    - 모멘텀과 학습률을 조절하는 방법을 절충해서 만들어진 Adam이라는 옵티마이즈도 있는데요.
    - Adam은 현재 가장 대표적으로 흔하게 사용되는 옵티마이즈입니다. 
    - 먼저 모멘텀 방식과 유사하게 **이전 그래디언트 방향과 크기를 기억**하고 이 정보를 현재의 업데이트에 사용하여 보다 안정적이고 일관된 업데이트를 가능하게 합니다.
    - 그리고 RMSProp 알고리즘과 유사한 방식으로 **각 가중치에 대해 그래디언트 변화률**을 보유하여 학습률을 개별적으로 조절할 수 있도록 하는데요.
    - 크게 변하는 그래디언트에 대해서는 학습률을 낮추고, 
    - 작게 변하는 그래디언트에 대해서는 상대적으로 높은 학습률을 유지하게 함으로써
    - 학습과정에서 안정성을 증가시키고 더 빠르고 효율적으로 최적점에 도달할 수 있도록 돕죠.
    - 수식에 대해서도 좀 더 자세히 살펴 보면, 
    - 먼저 모멘텀과 RMSProp에서 계산했던 수식이랑 비슷하게 v(t)와 g(t)를 계산합니다.
    - v(t) : 1차 모멘텀
    - g(t) : 2차 모멘텀
    - 학습 초기시 **v(t), g(t) 값이 0이 되는 것을 방지하기 위해 편향 보정 과정**을 사용합니다.

## 06. Normalization 기법 알아보기
1. 정규화 (Normalization)
    - 정규화는 데이터의 범위를 일정하게 조정하거나 데이터 분포를 표준화하는 과정이라고 할 수 있는데요.
    - 모델의 학습 속도를 빠르게 하고 과적합을 방지하는데 큰 도움이 됩니다.
    - 이런 정규화 과정은 데이터 전처리 단계에서 입력데이터에 적용될 수 있으며, 
    - 신경망의 내부에서 중간층의 활성화 함수 입력에도 적용될 수 있습니다.
    - 정규화를 적용하지 않은 상태에서는 모델의 최적화 과정에서
    - 전체 데이터를 잘 파악하지 못하고 **지역 최저점(Local minimum)**에 같혀
    - **전역 최저점(Global minimum)**을 찾지 못하는 경우가 발생할 수 있습니다.
    - 하지만 정규화를 적용하면 이러한 문제를 완화할 수 있어요.
    - 정규화된 데이터는 모델이 지역 최저점에서 쉽게 벗어나고 
    - 최적화 과정이 효율적으로 진행될 수 있도록 돕습니다.

2. 정규화의 목적
    - 정규화의 목적을 정리해 보자면, 
    - 정규화는 우선 입력 데이터의 특성들이 서로 다른 범위를 가지고 있을 때, 
    - 이를 **동일한 범위로 조정**함으로써, 모델이 학습하기 더 쉽게 만듭니다.
    - 예를 들어, **모든 특성값**을 0~1 또는 -1~1로 조정하는 스캐일링을 통해 
    - 모델이 여러 특성들을 동등하게 취급하도록 할 수 있죠.

3. 배치 정규화 (Batch Normalization)
    - 나아가 신경망 내부에서 중간층 **활성화 함수에 입력되는 값**을 정규화 함으로써
    - 학습을 더 안정적이고 빠르게 진행되도록 할 수 있습니다.
    - 이는 특히 깊은 네트워크에서 중요한데, 
    - 입력의 분포가 각 층을 지날 때마다 일정하게 유지되도록 만들어서
    - **효율적인 학습을 촉진할 수 있다.**
    - 이를 위해 **배치 정류화**라는 기법이 주로 사용 되는데요.
    - 이 기법의 핵심 아이디어는 **네트워크의 각 층에서 활성화 함수가 입력 받는 값을 정규화**하는 것입니다.
    - 이 과정은 평균과 분산을 통해 조정이 이루워지고, 
    - 이 조정 과정은 신경망의 일부로써 직접적으로 학습과정에 포함됩니다.
    - 즉 각 배치 별로 평균과 분산을 이용해 정규화를 수행하는 **별도의 레이어**를 신경망 내에 배치하여, 입력값에 변형된 분포가 나타나지 않도록 하는 거에요.
    - 이는 각 레이어를 통과하는 데이터가 일정한 통계적 특성을 유지하도록 함으로써 
    - **내부 공변량 변화**를 최소화 하고 전체 학습을 보다 안정적으로 만들죠.

4. 내부 공변량 변화 (Internal Covariate Shift)
    - 여기서 내부 공변량 변화는 네트워크의 각 층을 통과하면서 
    - **입력 데이터의 분포가 변하는 현상**을 말하는데요.
    - 각 층의 가중치가 학습 과정에서 계속 업데이트 되기 때문에, 
    - 네트워크의 초기층에서 사용된 데이터의 분포와 
    - 나중층에서 사용된 데이터의 분포가 달라질 수 있습니다.
    - 이런 분포의 변화는 학습을 더 어렵게 만들고, 
    - 특히 네트워크가 깊어질수록 그 효과가 커질 수 있으므로 
    - 정규화 과정을 통해 이를 방지하려는 거에요.
    - 배치 정규화 과정을 이러한 수식으로 이뤄지면, 몇 가지 단계로 이뤄집니다.

5. 배치 정규화 과정
    - 각 미니배치에 대해 입력값의 **평균과 분산**을 계산한다.
    - 그 다음 평균과 분산 값을 가지고, 각 입력값을 **정규화**합니다.
    - 이 정규화 과정은 각 입력값을 **표준화** 하여 평균이 0이고, 분산이 1이 되도록 저장해요
    - 마지막으로 **파라미터**를 곱하고, 더해서 계산을 해줍니다.
    - 여기있는 파라미터 값들은 학습을 통해 최적의 값을 찾게 됩니다.

6. 배치 정규화의 효과
    - 각 레이어를 거치며 발생할 수 있는 입력값의 변동을 효과적으로 제어할 수 있고,
    - 결과적으로 학습 속도를 높이며 더 안정적인 학습이 가능해 집니다.
    - 이 기법은 특히 깊은 신경망에서 그래디언트 소실이나 폭발 문제를 완화하는데 매우 효과적이며
    - 과적합을 방지하는데에도 도움을 줄 수 있어요.

## 07. Regularization 기법 알아보기
1. 규제화 (Regularization) 
    - 과적합을 방지하고 
    - 모델의 일반화 능력을 향상 시키는데 중요한 역할을 하는데요

2. 훈련 데이터에 과적합
    - 모델이 훈련 데이터에 너무 잘 맞춰져서, 새로운 데이터나 테스트 데이터에 대해서 성능이 저하된다는 것을 의미해요.
    - 이로 인해 훈련 데이터에 대해서는 매우 높은 성능을 보이지만, 테스트 데이터나 실제 상황에 대해서는 성능이 크게 떨어 질 수 있죠.
    - 이러한 문제를 해결하기 위해 다양한 **레귤러라이제이션** 기법을 통해 
    - 모델이 훈련 데이터에 과도하게 의존하지 않도록 돕고, 
    - 보다 일반적인 패턴을 학습할 수 있도록 만들어요.
    - 대표적인 규제화 기법 중 하나인 
        - **L1, L2 정규화**
        - **드롭아웃 (Dropout)**
        - **조기 종료 (Early Stopping)**
        - **데이터 증강 (Data Augmentation)**
    - 에 대해서 알아보겠습니다.

3. L1 정규화 (Lasso)
    - L1 정규화는 라소 라고 부르는데요. 
    - 기존 손실 함수에 이러한 값을 추가하는 것입니다.
    - 가중치의 절댓값에 비례하는 비용을 손실 함수에 추가하는 거에요.
    - 이 부분을 **정규화 항**이라고 합니다.
    - L1 정규화는 가중치 중 **일부를 정확히 0**으로 만들어, 
    - 결과적으로 모델을 더 단순하게 만드는 효과가 있습니다.

4. L2 정규화 (Ridge)
    - 반면에 L2 정규화 또는 릿찌는 
    - **가중치의 제곱을 손실 함수에 추가** 하여 
    - 가중치의 극단값에 **페널티를 주어** 과적합을 방지합니다.
    - L1과 L2의 차이점은 추가되는 정규화 항에 있다고 볼 수 있어요.

5. 드롭아웃 (Dropout)
    - 또 다른 규제화 기법인 **드롭아웃**은 
    - 훈련 과정 중 무작위로 **일부 뉴런을 비활성화** 시키는 방법입니다.
    - 이는 특정 뉴런이나 뉴런의 조합에 과도하게 의존하는 것을 방지하며
    - 각기 다른 뉴런의 조합을 통해 데이터를 학습하도록 만드는데요.
    - 예를 들어 Dropout Rate=0.5로 설정했다고 보면, 
    - 랜덤으로 전체 뉴런중 반을 제외 시키게 됩니다.

6. 조기 종료 (Early Stopping)
    - 검증 세트의 성능이 더 이상 개선되지 않을 때
    - 학습을 조기에 멈추는 방법입니다.
    - 모델이 불필요하게 오래 훈련되어 과적합이 발생하는 것을 막아주는 효과가 있는데요.
    - 딥러닝 모델을 학습시키다 보면, 일정 시간이 지나면, 
    - 검증 세트에 대한 손실값이 오히려 증가하는 양상을 보이는 경우가 많습니다.
    - 그래서 성능이 더이상 개선되지 않는 것 같으면 학습을 중간에 멈춰서 
    - **과적합을 방지**하는 거죠.

7. 데이터 증강 (Data Augmentation)
    - **데이터 오그멘테이션**은 이미지 데이터에 효과적인 기법으로 
    - 원본 데이터에 여러가지 변형을 가해 데이터의 양을 인위적으로 늘리는 방법입니다.
    - 이는 모델이 다양한 변형을 경험하게 함으로써 일반화 능력을 강화시키는데요.
    - 특히 이미지 데이터에서 널리 사용되며, 회전, 이동, 확대, 축소 등의 
    - 변형을 적용하여 모델의 일반화 능력을 향상시킵니다.
    - 다양한 데이터 증강 기법에 대해서는 다음 레슨에서 자세히 알아 보도록 할께요.

## 08. 데이터 증강 기법 알아보기
1. 이미지 회전(Image Rotation)

2. 이미지 크롭 (Image Crop)

3. 밝기, 대비, 채도 변경

4. 유의어 교체

5. 임의의 단어 삽입, 삭제


