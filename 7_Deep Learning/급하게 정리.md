정리하자면, SimpleConvNet이라는 클라스를 만들어서 단순한 합성곱 신경망을 만들어줬고, visualize_filter 파일에서는 이 과정을 이용하여 랜덤 초기화한 Convolution층과 이미 학습된 Convolution층이 어떻게 다른지 시각화해줬고, 이미 학습이 완료된 params.pkl 파일에는 우리가 생략한 세세하게 활성화 함수, 하이퍼파라미터 튜닝 등등을 설정하는 과정이 들어가 있었다고 하면 맞을까요?
마지막 부분 수정 -> '하이퍼 파라미터가 튜닝된 후 필터까지 학습된 신경망이 들어있다'

import os, sys
print(os.getcwd())
current_dir = os.path.dirname(os.getcwd())
print(current_dir)
os.chdir(current_dir)

import numpy as np
import matplotlib.pyplot as plt

from dataset.mnist import load_mnist
from ch06.simple_convent import SimpleConvNet
from common.trainer import Trainer

#데이터 읽기
(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)

# 시간이 오래 걸릴 경우 데이터를 줄인다.
x_train, t_rain = x_train[:5000], t_train[:5000]
x_test, t_test = x_test[:1000], t_test[:1000]

max_epochs = 20

# 필터 갯수를 30개로 설정
# 필터 크기 5 X 5
network = SimpleConvNet(input_dim=(1,28,28), 
                        conv_param = {'filter_num': 30, 'filter_size':5, 'pad': 0, 'stride':1},
                        hidden_size=100, output_size=10, weight_init_std=0.01)
trainer = Trainer(network, x_train, t_train, x_test, t_test, epochs=max_epochs, mini_batch_size=100, optimizer='Adam', optimizer_param={'lr':0.001}, evaluate_sample_num_per_epoch=1000)
trainer.train()

# 매개변수 보존
network.save_params("params.pkl")
print("Saved Network Parameters!")
